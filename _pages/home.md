---
title: "Star-AI Lab - Home"
layout: homelay
excerpt: "Secure, Trustworthy, and Reliable AI Lab."
sitemap: false
permalink: /
---

#### At Star-AI (&#9733;AI) Lab, we focus on cutting-edge research to make the online space safer.

#### To this end, we develop novel methods in three key areas: AI-enabled cybersecurity, Security of AI, and Privacy of AI. Please see our **[current projects](https://star-ailab.github.io/research/)** and **[publications](https://star-ailab.github.io/publications/)** in each area from our **[team](https://star-ailab.github.io/team/)** ðŸ˜Š .

### Recent News

<div markdown="0" class="wrapper" style="border-bottom: 1px solid $black <!--$grey-color-->; border:4px; height:300px; overflow:auto;">
	<ul class="awards" style="margin-bottom: -5px">
		<li>Our paper, Trustworthy Federated Learning with Local Differential Privacy received the <b>Best Paper Award in WITS</b> 2025 (selected from 156 papers). </li>
		<br>
		<li>Our paper, <a href="https://arxiv.org/abs/2309.03791"> Optimal Transport Regularized Divergences: Application to Adversarial Robustness</a> was accepted to <b>SIAM</b> 2025. </li>
		<br>
		<li>Our paper, <a href="https://doi.org/10.25300/MISQ/2024/17339"> RADAR: A Framework for Developing Adversarially Robust Cyber Defense AI Agents with Deep Reinforcement Learning </a> was accepted to <b>MIS Quarterly</b> 2025 (~10% acceptance rate). </li>
		<br>
		<li>Our paper, <a href="https://openreview.net/forum?id=irrtPRFksw"> Risk-Sensitive Variational Actor-Critic: A Model-Based Approach</a> was accepted to <b>ICLR</b> 2025. </li>
		<br>
		<li>Our paper, <a href="https://www.tandfonline.com/doi/epdf/10.1080/07421222.2025.2561384?needAccess=true"> Defending Deep Learning-Based Raw Malware Detectors Against Adversarial Attacks: A Sequence Modeling Approach </a> was accepted to <b> JMIS 2025</b>. </li>
		<br>
		<li>Our paper, <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10994375"> Efficient Full-Stack Private Federated Deep Learning with Post-Quantum Security </a> was accepted to <b> TDSC </b> 2025. </li>	
		<br>
		<li>Our paper, <a href="https://arxiv.org/pdf/2408.10456"> Differentially Private Stochastic Gradient Descent with Fixed-Size Minibatches: Tighter RDP Guarantees with or without Replacement</a> was accepted to <b>NeurIPS</b> 2024. </li>
		<br>
		<li>Our paper, <a href="https://www.researchgate.net/publication/384676652_Learning_Contextualized_Action_Representations_in_Sequential_Decision_Making_for_Adversarial_Malware_Optimization"> Learning Contextualized Action Representations in Sequential Decision Making for Adversarial Malware Optimization</a> was accepted to <b>TDSC</b> 2024. </li>
		<br>
		<li>Our paper, <a href="https://arxiv.org/pdf/2304.03841"> Efficient Secure Aggregation for Privacy-Preserving Federated Machine Learning</a> was accepted to <b>ACSAC</b> 2024. </li>
		<br>
		<li>Reza serves as a <b>PC member</b> in <a href ="https://dls2023.ieee-security.org/"> IEEE S&P Workshop on Deep Learning Security and Privacy 2023 </a>.</li>
		<br>
		<li>Reza helps organize <b>IEEE ICDM Workshop</b> on <a href="https://ml4cyber.github.io/23/"> Machine Learning for Cybersecurity (MLC) 2023 </a>. </li>
		<br>
		<li>Our paper, <a href="https://ieeexplore.ieee.org/document/9744510"> Heterogeneous Domain Adaptation with Deep Adversarial Representation Learning: Experiments on E-Commerce and Cybersecurity</a> was accepted to <b>IEEE TPAMI</b> 2022.</li>
		<br>
		<li>Our paper, <a href="https://dl.acm.org/doi/full/10.1145/3505226"> Counteracting Dark Web Text-Based CAPTCHA with Generative Adversarial Learning for Proactive Cyber Threat Intelligence</a> was accepted to <b>ACM TMIS</b> 2022.</li>
		<br>
		<li>Our paper, Single-Shot Black-Box Adversarial Attacks Against Malware Detectors: A Causal Language Model Approach was accepted to <b>IEEE ISI</b> 2021.</li>
		<br>
		<li>Our paper on <a href="https://arxiv.org/abs/2111.09415"> Deep Learning-based Privacy Awareness </a> received the <i> Best Paper Award</i> in <b>IEEE ISI</b> 2021.</li>
		<br>
		<li>Reza serves as <b>Program Committee (PC) Member</b> in <b>IEEE S&P Workshop</b> on Deep Learning and Security (DLS) 2022.</li>
		<br>
		<li>Our paper, on <a href="https://ieeexplore.ieee.org/document/9474314"> Binary Black-Box Attacks Against Static Malware Detectors with Reinforcement Learning in Discrete Action Spaces</a> was accepted at <b>IEEE S&P</b> Workshop on Deep Learning and Security (DLS) 2021.</li>
		<br>
		<li>Our paper, <a href="https://arxiv.org/abs/2012.07994"> Binary Black-box Evasion Attacks Against Deep Learning-based Static Malware Detectors with Adversarial Byte-Level Language Model</a> was accepted to the <b>AAAI</b> Conference on Artificial Intelligence, Workshop on Robust, Secure, and Efficient Machine Learning (RSEML), 2021.</li>
		<br>
		<li>Our Paper on Adversarial Cross-Lingual Knowledge Transfer in Hacker Forums was accepted at <b>IEEE S&P</b> Workshop on Deep Learning and Security (DLS).</li>
		<br>
	</ul>
</div>

### Founder's Bio, [Curriculum vitae](/files/Ebrahimi_CV_2025.pdf), and [Google Scholar](https://scholar.google.com/citations?user=4DmURbEAAAAJ&hl=en) 
<div class="col-sm-12 clearfix">
  <a href="https://scholar.google.com/citations?user=4DmURbEAAAAJ&hl=en"> <img src="{{ site.url }}{{ site.baseurl }}/images/teampic/rebrahimi.jpg" class="img-responsive" width="25%" style="float: left; padding:8px" /></a>
  <h4>&nbsp;&nbsp; <a href="https://scholar.google.com/citations?user=4DmURbEAAAAJ&hl=en"> Reza Ebrahimi </a></h4>
  <i>&nbsp;&nbsp; ebrahimim[ at ]usf.edu</i>
  <!--<p>&nbsp;&nbsp; Reza is an assistant professor and the director of Star-AI Lab at School of Information Systems and <br>&nbsp;&nbsp; Management (SISM) at the University of South Florida. He received his Ph.D. in Information Systems from <br>&nbsp;&nbsp; the University of Arizona, where he was a research assistant at the Artifical Intelligence (AI) Lab conducted <br>&nbsp;&nbsp; by Regentsâ€™ Professor Hsinchun Chen. In 2016, He received his Master's in Computer Science from <br>&nbsp;&nbsp; Concordia University in Montreal, Canada. His Ph.D. Thesis targets two interconnected research areas: <br>&nbsp;&nbsp; Security of AI and AI for Security. His Master's thesis leveraged crime data mining to enhance juveniles' <br>&nbsp;&nbsp; safety in the cyberspace.</p>-->
  <p>Reza is an assistant professor and the founder of Star-AI Lab at the School of Information Systems and a fellow of the Rapid7 Cyber Threat Intelligence Lab at the University of South Florida (USF). He received his Ph.D. in Management Information Systems from the University of Arizona, where he was a research associate at the Artificial Intelligence (AI) Lab in 2021. He received his masterâ€™s degree in Computer Science from Concordia University, Canada, in 2016. His Masterâ€™s thesis leveraged crime data mining to enhance juvenilesâ€™ safety in cyberspace. Rezaâ€™s PhD dissertation on AI-enabled cybersecurity analytics won the ACM SIGMIS best doctoral dissertation award in 2021. Rezaâ€™s research focuses on statistical and adversarial machine learning for AI-enabled secure and trustworthy cyberspace.</p>
  <p>Reza has published over 40 articles in peer reviewed journals, conferences, and workshops, including NeurIPS, ICLR, SIAM, IEEE TPAMI, IEEE TDSC, IEEE S&PW, IEEE ACSAC, AAAIW, IEEE ISI, IEEE ICDMW, Applied Artificial Intelligence, Digital Forensics, MIS Quarterly, and JMIS. He has been serving as a Program Chair and Program Committee member in IEEE ICDM Workshop on Machine Learning for Cybersecurity (MLC) and IEEE S&P Workshop on Deep Learning Security and Privacy (DLSP). He servs as an organizer of 2025 IEEE S&P Workshop on Human-Machine Intelligence for Security Analytics (HMI-SA). He has contributed to several projects supported by the National Science Foundation (NSF). He is an IEEE Senior Member and a member of the ACM, AAAI, and AIS.</p>
  
</div>










